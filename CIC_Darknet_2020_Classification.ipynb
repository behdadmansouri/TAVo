{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ecfdbb7-703d-41bd-9a4c-7693cbca54f6",
      "metadata": {
        "id": "4ecfdbb7-703d-41bd-9a4c-7693cbca54f6"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.under_sampling import CondensedNearestNeighbour, RandomUnderSampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b64f4bc1-f9e5-44d4-ba8b-936809482bb5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b64f4bc1-f9e5-44d4-ba8b-936809482bb5",
        "outputId": "31fe05d5-9d01-4b93-f748-faf0038dfa99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "b'Skipping line 328: expected 85 fields, saw 125\\n'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Audio-Streaming', 'Browsing', 'Chat', 'Email', 'File-Transfer',\n",
              "       'P2P', 'Video-Streaming', 'VOIP'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 217
        }
      ],
      "source": [
        "data = pd.read_csv(\"Darknet.CSV\", low_memory=False, parse_dates=[\"Timestamp\"], error_bad_lines=False)\n",
        "\n",
        "def display_all(df): # tip: you can transpose before giving input!\n",
        "    with pd.option_context(\"display.max_rows\", 1000, \"display.max_columns\", 1000): \n",
        "        print(\"The shape is: \", data.shape)\n",
        "        data.info()\n",
        "        data.dtypes\n",
        "        display(df)\n",
        "        \n",
        "\n",
        "def display_types(df):\n",
        "    print(df[\"Level1\"].unique())\n",
        "    print(df[\"Level2\"].unique())\n",
        "    print(df.groupby(\"Level1\")[\"Level2\"].unique())\n",
        "    print(df.groupby(\"Level1\")[\"Level2\"].nunique())\n",
        "    \n",
        "# TODO drop VPN\n",
        "data.drop([\"Flow ID\"],axis = 1,inplace = True)\n",
        "data.drop([\"Src IP\"],axis = 1,inplace = True)\n",
        "data.drop([\"Dst IP\"],axis = 1,inplace = True)\n",
        "data.drop([\"Src Port\"],axis = 1,inplace = True)\n",
        "data.drop([\"Dst Port\"],axis = 1,inplace = True)\n",
        "data.drop([\"Flow Duration\"],axis = 1,inplace = True)\n",
        "data.drop([\"Timestamp\"],axis = 1,inplace = True)\n",
        "# data.drop_duplicates(subset=None, keep='first', inplace=True, ignore_index=False)\n",
        "# data = data.loc[:, internet_ds_test.apply(pd.Series.nunique) != 1]\n",
        "data.isnull().sum()\n",
        "\n",
        "data.rename(columns = {\"Label\" : \"Level1\", \"Label.1\" : \"Level2\"}, inplace = True)\n",
        "# data.rename({'Level2': {\"AUDIO-STREAMING\" : \"Audio-Streaming\", \"Audio-streaming\" : \"Audio-Streaming\", \"Video-streaming\" : \"Video-Streaming\", \"File-transfer\" : \"File-Transfer\"}}, inplace = True)\n",
        "data['Level2'].loc[data['Level2'] == 'AUDIO-STREAMING'] = 'Audio-Streaming'\n",
        "data['Level2'].loc[data['Level2'] == 'Audio-streaming'] = 'Audio-Streaming'\n",
        "data['Level2'].loc[data['Level2'] == 'File-transfer'] = 'File-Transfer'\n",
        "data['Level2'].loc[data['Level2'] == 'Video-streaming'] = 'Video-Streaming'\n",
        "data[\"Level2\"].unique()\n",
        "# samples[real_columns] = samples[real_columns].replace([np.inf, -np.inf], np.nan)\n",
        "# samples[real_columns] = samples[real_columns].dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c402410c-13cf-4923-ab4a-318a98804811",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c402410c-13cf-4923-ab4a-318a98804811",
        "outputId": "660b5169-ed74-4cc2-f3cf-4134c39aae08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory usage after optimization is: 31.31 MB\n",
            "Decreased by 62.8%\n"
          ]
        }
      ],
      "source": [
        "start_mem = data.memory_usage().sum() / 1024**2 # start mem for comparison later\n",
        "\n",
        "for col in data.columns:\n",
        "    col_type = data[col].dtypes\n",
        "    if col_type in ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']:\n",
        "        c_min = data[col].min()\n",
        "        c_max = data[col].max()\n",
        "        if str(col_type)[:3] == 'int': # if it's int\n",
        "            if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max: # if it can be int8, make it int8\n",
        "                data[col] = data[col].astype(np.int8)\n",
        "            elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max: # if it can be int16, make it int16\n",
        "                data[col] = data[col].astype(np.int16)\n",
        "            elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max: # so on\n",
        "                data[col] = data[col].astype(np.int32)\n",
        "            elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                data[col] = data[col].astype(np.int64)\n",
        "        else: # if it's float\n",
        "            if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max: # if it can be float16, make it float16\n",
        "                data[col] = data[col].astype(np.float16)\n",
        "            elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max: # so on\n",
        "                data[col] = data[col].astype(np.float32)\n",
        "            else:\n",
        "                data[col] = data[col].astype(np.float64)\n",
        "\n",
        "end_mem = data.memory_usage().sum() / 1024**2 # end mem for comparison later\n",
        "\n",
        "print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b51358c-6066-4f78-a0d0-807ea45f9fd7",
      "metadata": {
        "id": "7b51358c-6066-4f78-a0d0-807ea45f9fd7"
      },
      "source": [
        "# Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0331bfd-8215-40c5-ad7f-2b6605dc1452",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0331bfd-8215-40c5-ad7f-2b6605dc1452",
        "outputId": "85d51058-8d15-4727-83d5-82bdb12c63a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 219
        }
      ],
      "source": [
        "copied = data.copy()\n",
        "copied.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "copied = copied.dropna()\n",
        "copied.isnull().sum().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07d8a744-1ee5-43c3-ae72-76ff620269d8",
      "metadata": {
        "id": "07d8a744-1ee5-43c3-ae72-76ff620269d8"
      },
      "outputs": [],
      "source": [
        "copied = copied[(copied.Level1 == 'Tor') | (copied.Level1 == 'Non-Tor')]  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "982fac89-b17a-401e-9f97-278c1608cf5e",
      "metadata": {
        "id": "982fac89-b17a-401e-9f97-278c1608cf5e"
      },
      "outputs": [],
      "source": [
        "Y = copied[[\"Level1\", \"Level2\"]]\n",
        "X = copied.drop([\"Level1\", \"Level2\"], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48bc5460-6405-4efd-9864-31a6aced02f6",
      "metadata": {
        "id": "48bc5460-6405-4efd-9864-31a6aced02f6"
      },
      "outputs": [],
      "source": [
        "Y.replace('Tor', 1, inplace=True)               #Converting strings to binary classes 0 or 1\n",
        "Y.replace('Non-Tor', 0, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f34c3bc3-0387-4fc7-8462-b9c55fc8f28d",
      "metadata": {
        "id": "f34c3bc3-0387-4fc7-8462-b9c55fc8f28d"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "def categorise(row):\n",
        "    if row['Level1'] == 1:\n",
        "        return f\"Tor {row['Level2']}\"\n",
        "    else:\n",
        "        return 'Non-Tor'\n",
        "    \n",
        "\n",
        "Y['Level2'] = Y.apply(lambda row: categorise(row), axis = 1)\n",
        "\n",
        "le = LabelEncoder()\n",
        "Y['Level2'] = le.fit_transform(Y['Level2'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5773fe04-0ddf-40d6-bffb-c36f3215c08b",
      "metadata": {
        "id": "5773fe04-0ddf-40d6-bffb-c36f3215c08b"
      },
      "outputs": [],
      "source": [
        "X_train__test, X_application, Y_train_test, Y_application = train_test_split(X, Y, test_size=0.30, random_state=42, stratify=Y['Level2'])\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_train__test, Y_train_test, test_size=0.30, random_state=42, stratify=Y_train_test['Level2'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9747d62-5e79-4ea4-b515-3a6bd737cf09",
      "metadata": {
        "id": "e9747d62-5e79-4ea4-b515-3a6bd737cf09"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce4503f6-7255-425d-a57c-108b5f828607",
      "metadata": {
        "id": "ce4503f6-7255-425d-a57c-108b5f828607"
      },
      "source": [
        "# Training and Testing Models\n",
        "## Layer 1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Undersampling minority classes from layer 2"
      ],
      "metadata": {
        "id": "Wb46TmYokiFh"
      },
      "id": "Wb46TmYokiFh"
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train_l = Y_train['Level1']\n",
        "Y_test_l = Y_test['Level1']"
      ],
      "metadata": {
        "id": "6dLpHJh_soIc"
      },
      "id": "6dLpHJh_soIc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train_2 = Y_train['Level2']\n",
        "Y_test_2 = Y_test['Level2']"
      ],
      "metadata": {
        "id": "4xj_p6TZsnhI"
      },
      "id": "4xj_p6TZsnhI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(Y_train_2, return_counts=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vq7GvpsYs9Z",
        "outputId": "19714a0e-8769-482d-9536-007b8467bcf1"
      },
      "id": "5vq7GvpsYs9Z",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1, 2, 3, 4, 5, 6, 7, 8]),\n",
              " array([45721,   110,   129,    31,     6,    53,   108,   146,    99]))"
            ]
          },
          "metadata": {},
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampless = {1: 110, 2: 129, 6:108, 7:146}\n",
        "samples = [1, 2, 6, 7]\n",
        "undersample = CondensedNearestNeighbour(sampling_strategy = samples, random_state = 42, n_jobs=-1, n_neighbors=3)\n",
        "#undersample = RandomUnderSampler(sampling_strategy = sampless, random_state = 42)\n",
        "#X_train, Y_train_2 = undersample.fit_resample(X_train, Y_train_2)"
      ],
      "metadata": {
        "id": "LqcdZCEdkgo3"
      },
      "id": "LqcdZCEdkgo3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Y_train['Level2'].value_counts()"
      ],
      "metadata": {
        "id": "tM1JQ_H7XAoB"
      },
      "id": "tM1JQ_H7XAoB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a target Y for binary after undersampling\n",
        "\n",
        "Y_train_l1 = Y_train_2.copy()\n",
        "Y_train_l1[Y_train_l1>1] = 1\n",
        "Y_train_l.equals(Y_train_l1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3fCAy72Zqje",
        "outputId": "0604c537-72a5-4aeb-9f5a-5c4c197ae653"
      },
      "id": "t3fCAy72Zqje",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab901c30-b0f9-4364-8f41-0a285c459394",
      "metadata": {
        "id": "ab901c30-b0f9-4364-8f41-0a285c459394"
      },
      "outputs": [],
      "source": [
        "#Using only the first classification for the gridsearch\n",
        "#Y_train_l = Y_train['Level1']\n",
        "#Y_test_l = Y_test['Level1']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.info(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiq-DvMTonsR",
        "outputId": "1317a9e5-7d21-4b42-f541-06464c326d76"
      },
      "id": "wiq-DvMTonsR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class:  ndarray\n",
            "shape:  (46403, 76)\n",
            "strides:  (8, 371224)\n",
            "itemsize:  8\n",
            "aligned:  True\n",
            "contiguous:  False\n",
            "fortran:  True\n",
            "data pointer: 0x19ece000\n",
            "byteorder:  little\n",
            "byteswap:  False\n",
            "type: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "U60OZQbhnfbD"
      },
      "id": "U60OZQbhnfbD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fm7438KcpNCk",
        "outputId": "12e3fdb7-eb70-4d7f-a571-53383abfb535"
      },
      "id": "Fm7438KcpNCk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(46403, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 235
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f8787f3-4c2b-4d35-9185-28cd3006ca9c",
      "metadata": {
        "id": "7f8787f3-4c2b-4d35-9185-28cd3006ca9c"
      },
      "outputs": [],
      "source": [
        "#importing libraries for models\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier, GradientBoostingClassifier, BaggingClassifier, AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import xgboost as xgb\n",
        "from imblearn.pipeline import Pipeline as impip\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "\n",
        "#Creating classifiers to be passed to the pipeline\n",
        "clf1 = RandomForestClassifier(random_state=42, criterion = 'entropy')\n",
        "clf2 = ExtraTreesClassifier(random_state=42, criterion = 'entropy')\n",
        "clf3 = DecisionTreeClassifier(random_state=42, criterion = 'entropy')\n",
        "clf4 = GradientBoostingClassifier(random_state=42)\n",
        "clf5 = AdaBoostClassifier(random_state=42)\n",
        "clf6 = BaggingClassifier(random_state=42)\n",
        "clf7 = SVC(random_state=42)\n",
        "\n",
        "#Initializing parameter dictionary for models\n",
        "\n",
        "param1 = {}\n",
        "param1['classifier__n_estimators'] = [10, 50, 100]\n",
        "param1['classifier__max_depth'] = [5, 10, 20]\n",
        "param1['classifier__min_samples_split'] = [2,5,10]\n",
        "param1['classifier'] = [clf1]\n",
        "\n",
        "param2 = {}\n",
        "param2['classifier__n_estimators'] = [10, 50, 100]\n",
        "param2['classifier__max_depth'] = [5, 10, 20]\n",
        "param2['classifier__min_samples_split'] = [2,5,10]\n",
        "param2['classifier'] = [clf2]\n",
        "\n",
        "param3 = {}\n",
        "param3['classifier__max_depth'] = [5, 10, 20]\n",
        "param3['classifier__min_samples_split'] = [2,5,10]\n",
        "param3['classifier'] = [clf3]\n",
        "\n",
        "param4 = {}\n",
        "param4['classifier__n_estimators'] = [10, 50, 100]\n",
        "param4['classifier__learning_rate'] = [0.01, 0.05, 0.1]\n",
        "param4['classifier__max_depth'] = [5, 10, 20]\n",
        "param3['classifier__min_samples_split'] = [2,5,10]\n",
        "param4['classifier'] = [clf4]\n",
        "\n",
        "param5 = {}\n",
        "param5['classifier__n_estimators'] = [10, 50, 100]\n",
        "param5['classifier__learning_rate'] = [0.01, 0.05, 0.1]\n",
        "param5['classifier'] = [clf5]\n",
        "\n",
        "param6 = {}\n",
        "param6['classifier__n_estimators'] = [10, 50, 100]\n",
        "param6['classifier__max_samples'] = [0.05, 0.1, 0.2, 0.5]\n",
        "param6['classifier'] = [clf6]\n",
        "\n",
        "param7 = {}\n",
        "param7['classifier__C'] = [0.01, 0.1, 1, 5]\n",
        "param7['classifier__kernel'] = ['linear', 'rbf', 'sigmoid']\n",
        "param7['classifier'] = [clf7]\n",
        "\n",
        "params = [param1, param2, param3, param4, param5, param6, param7]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4de895b2-f06c-4326-8ff7-67aeefc0c700",
      "metadata": {
        "id": "4de895b2-f06c-4326-8ff7-67aeefc0c700"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, classification_report,confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbe26285-044a-4b82-a3a3-22a882e9d4c9",
      "metadata": {
        "tags": [],
        "id": "fbe26285-044a-4b82-a3a3-22a882e9d4c9"
      },
      "outputs": [],
      "source": [
        "#Creating random_state=ne for the models\n",
        "# pipeline = impip([('scaler', StandardScaler()),('classifier', clf1),])\n",
        "\n",
        "# #implementing randomized search because gridsearch takes forever\n",
        "# rs = RandomizedSearchCV(pipeline, params, cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42), n_jobs=-1, scoring='f1', error_score='raise').fit(X_train, Y_train_l)\n",
        "# rs.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5aa8c65-5118-4ef2-939c-b94d0ba1bfc7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5aa8c65-5118-4ef2-939c-b94d0ba1bfc7",
        "outputId": "ca8fde13-457b-4899-bf8b-9ade61a3ce1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score [1. 1.]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     19595\n",
            "           1       1.00      1.00      1.00       292\n",
            "\n",
            "    accuracy                           1.00     19887\n",
            "   macro avg       1.00      1.00      1.00     19887\n",
            "weighted avg       1.00      1.00      1.00     19887\n",
            "\n",
            "Confusion Matrix \n",
            "[[19595     0]\n",
            " [    0   292]]\n"
          ]
        }
      ],
      "source": [
        "# random Forest worked best\n",
        "ranForModel = RandomForestClassifier(n_estimators=10, criterion = \"entropy\")\n",
        "ranForModel.fit(X_train, Y_train_l)\n",
        "prediction_1 = ranForModel.predict(X_test)\n",
        "Accuracy = accuracy_score(Y_test_l, prediction_1)\n",
        "print(\"F1 score\",f1_score(Y_test['Level1'], prediction_1, average=None))\n",
        "print(classification_report(Y_test['Level1'], prediction_1, target_names=['0','1']))\n",
        "print('Confusion Matrix \\n' + str(confusion_matrix(Y_test['Level1'], prediction_1)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "231271af-4560-48d8-8218-9873ca0e628f",
      "metadata": {
        "id": "231271af-4560-48d8-8218-9873ca0e628f"
      },
      "source": [
        "## Layer 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "770c02af-0281-4f8a-847b-13f62ed4dc99",
      "metadata": {
        "id": "770c02af-0281-4f8a-847b-13f62ed4dc99"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "#Creating classifiers to be passed to the pipeline\n",
        "models = list()\n",
        "models.append(('rfc', RandomForestClassifier(random_state=42, criterion = 'entropy')))\n",
        "models.append(('etc', ExtraTreesClassifier(random_state=42, criterion = 'entropy')))\n",
        "models.append(('dtc', DecisionTreeClassifier(random_state=42, criterion = 'entropy')))\n",
        "models.append(('gbc', GradientBoostingClassifier(random_state=42)))\n",
        "models.append(('abc', AdaBoostClassifier(random_state=42)))\n",
        "models.append(('bc', BaggingClassifier(random_state=42)))\n",
        "models.append(('svm', SVC(random_state=42, probability=True)))\n",
        "\n",
        "ensemble = VotingClassifier(estimators=models, voting='soft')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3e2e10e-ce3a-4acb-826a-99be936ad271",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3e2e10e-ce3a-4acb-826a-99be936ad271",
        "outputId": "9387f7bf-9a26-40b4-df81-35623e303198"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingClassifier(estimators=[('rfc',\n",
              "                              RandomForestClassifier(criterion='entropy',\n",
              "                                                     random_state=42)),\n",
              "                             ('etc',\n",
              "                              ExtraTreesClassifier(criterion='entropy',\n",
              "                                                   random_state=42)),\n",
              "                             ('dtc',\n",
              "                              DecisionTreeClassifier(criterion='entropy',\n",
              "                                                     random_state=42)),\n",
              "                             ('gbc',\n",
              "                              GradientBoostingClassifier(random_state=42)),\n",
              "                             ('abc', AdaBoostClassifier(random_state=42)),\n",
              "                             ('bc', BaggingClassifier(random_state=42)),\n",
              "                             ('svm', SVC(probability=True, random_state=42))],\n",
              "                 voting='soft')"
            ]
          },
          "metadata": {},
          "execution_count": 241
        }
      ],
      "source": [
        "#Y_train_2 = Y_train['Level2']\n",
        "#Y_test_2 = Y_test['Level2']\n",
        "\n",
        "\n",
        "ensemble.fit(X_train, Y_train_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "caa4e779-09a0-40b9-8a66-001c52811402",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caa4e779-09a0-40b9-8a66-001c52811402",
        "outputId": "5ee5e0ad-06e2-4b72-dd87-520d5d555177"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score [0.99994897 0.91489362 0.85185185 0.70967742 0.5        0.84\n",
            " 0.95652174 0.91935484 0.79012346]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     19595\n",
            "           1       0.91      0.91      0.91        47\n",
            "           2       0.87      0.84      0.85        55\n",
            "           3       0.65      0.79      0.71        14\n",
            "           4       1.00      0.33      0.50         3\n",
            "           5       0.75      0.95      0.84        22\n",
            "           6       0.96      0.96      0.96        46\n",
            "           7       0.93      0.90      0.92        63\n",
            "           8       0.82      0.76      0.79        42\n",
            "\n",
            "    accuracy                           1.00     19887\n",
            "   macro avg       0.88      0.83      0.83     19887\n",
            "weighted avg       1.00      1.00      1.00     19887\n",
            "\n",
            "Confusion Matrix \n",
            "[[19594     0     0     0     0     0     0     0     1]\n",
            " [    0    43     2     1     0     0     1     0     0]\n",
            " [    0     1    46     5     0     1     1     0     1]\n",
            " [    0     0     1    11     0     2     0     0     0]\n",
            " [    0     0     0     0     1     2     0     0     0]\n",
            " [    0     1     0     0     0    21     0     0     0]\n",
            " [    0     0     2     0     0     0    44     0     0]\n",
            " [    0     1     0     0     0     0     0    57     5]\n",
            " [    1     1     2     0     0     2     0     4    32]]\n"
          ]
        }
      ],
      "source": [
        "prediction_2 = ensemble.predict(X_test)\n",
        "print(\"F1 score\",f1_score(Y_test['Level2'], prediction_2, average=None))\n",
        "print(classification_report(Y_test['Level2'], prediction_2, target_names=['0','1','2','3','4','5','6','7','8']))\n",
        "print('Confusion Matrix \\n' + str(confusion_matrix(Y_test['Level2'], prediction_2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e760127a-bea7-4d12-bf01-f7936f7d5f4e",
      "metadata": {
        "id": "e760127a-bea7-4d12-bf01-f7936f7d5f4e"
      },
      "source": [
        "## Critique Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccfd2b53-8d47-4263-ad75-a8a2ed5a40e9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccfd2b53-8d47-4263-ad75-a8a2ed5a40e9",
        "outputId": "6bc21436-5bbe-441e-ccb6-8ef5f490b309"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(max_depth=10, n_estimators=250, n_jobs=-1, random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 243
        }
      ],
      "source": [
        "decTree = DecisionTreeClassifier(criterion = \"entropy\", max_depth=10, min_samples_split=2)\n",
        "decTree.fit(X_train, Y_train_l)\n",
        "xgb = xgb.XGBClassifier(n_estimators=250, n_jobs=-1, random_state=42, max_depth=10)\n",
        "xgb.fit(X_train, Y_train_l)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c33b8fa0-8f39-413e-878e-d86c07b995c5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c33b8fa0-8f39-413e-878e-d86c07b995c5",
        "outputId": "dec15742-79f3-4032-cfdd-37565fc4289c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score [1. 1.]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     19595\n",
            "           1       1.00      1.00      1.00       292\n",
            "\n",
            "    accuracy                           1.00     19887\n",
            "   macro avg       1.00      1.00      1.00     19887\n",
            "weighted avg       1.00      1.00      1.00     19887\n",
            "\n",
            "Confusion Matrix \n",
            "[[19595     0]\n",
            " [    0   292]]\n"
          ]
        }
      ],
      "source": [
        "predictions_3 = xgb.predict(X_test)\n",
        "print(\"F1 score\",f1_score(Y_test['Level1'], predictions_3, average=None))\n",
        "print(classification_report(Y_test['Level1'], predictions_3, target_names=['0','1']))\n",
        "print('Confusion Matrix \\n' + str(confusion_matrix(Y_test['Level1'], predictions_3)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a65a012b-5c77-4489-881a-5c0bfe69503f",
      "metadata": {
        "id": "a65a012b-5c77-4489-881a-5c0bfe69503f"
      },
      "source": [
        "# Dynamic Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d5e6ec6-0473-4ed4-94ce-1bf1c0b3460b",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d5e6ec6-0473-4ed4-94ce-1bf1c0b3460b",
        "outputId": "3d609b25-790e-47b2-e68c-6079a84df625"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Critic! [1, 0, 1] 0\n",
            "Critic! [1, 0, 1] 1\n",
            "Critic! [1, 0, 1] 1\n"
          ]
        }
      ],
      "source": [
        "# passing only the TOR entries to the second layer\n",
        "all_preds = []\n",
        "for index in range(X_application.shape[0]):\n",
        "    \n",
        "    obs = scaler.transform([X_application.iloc[index].values])\n",
        "    obs = obs.flatten()\n",
        "    final_pred = 0\n",
        "    #first layer:\n",
        "    pred1 = ranForModel.predict([obs])[0]\n",
        "    final_pred = pred1\n",
        "    \n",
        "    if pred1 == 1:\n",
        "        pred2 = ensemble.predict([obs])[0]\n",
        "        final_pred = pred2\n",
        "    else:\n",
        "        pred2 = 'N'\n",
        "        \n",
        "    if pred2 == 0:\n",
        "        pred3 = xgb.predict([obs])[0]\n",
        "        print('Critic! ' + str([pred1, pred2, pred3]) + ' ' + str(Y_application.iloc[index, 0]))\n",
        "        final_pred = pred3\n",
        "    else:\n",
        "        pred3 = 'N'\n",
        "            \n",
        "    all_preds.append([pred1, pred2, pred3, final_pred])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "031f6b30-bb2d-4c74-a3d7-3cedf941fb9d",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "031f6b30-bb2d-4c74-a3d7-3cedf941fb9d",
        "outputId": "d7bf7cfa-016c-48a0-d9c6-1a5c489a9c5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score [0.99987498 0.86956522 0.88157895 0.84444444 0.4        0.91176471\n",
            " 0.95522388 0.92485549 0.84745763]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     27993\n",
            "           1       0.85      0.90      0.87        67\n",
            "           2       0.92      0.85      0.88        79\n",
            "           3       0.76      0.95      0.84        20\n",
            "           4       1.00      0.25      0.40         4\n",
            "           5       0.86      0.97      0.91        32\n",
            "           6       0.94      0.97      0.96        66\n",
            "           7       0.95      0.90      0.92        89\n",
            "           8       0.88      0.82      0.85        61\n",
            "\n",
            "    accuracy                           1.00     28411\n",
            "   macro avg       0.91      0.84      0.85     28411\n",
            "weighted avg       1.00      1.00      1.00     28411\n",
            "\n",
            "Confusion Matrix \n",
            "[[27991     1     0     1     0     0     0     0     0]\n",
            " [    0    60     4     0     0     0     1     0     2]\n",
            " [    0     6    67     4     0     0     2     0     0]\n",
            " [    0     0     1    19     0     0     0     0     0]\n",
            " [    0     0     0     0     1     3     0     0     0]\n",
            " [    0     0     0     0     0    31     0     0     1]\n",
            " [    0     2     0     0     0     0    64     0     0]\n",
            " [    2     1     1     0     0     0     1    80     4]\n",
            " [    3     1     0     1     0     2     0     4    50]]\n"
          ]
        }
      ],
      "source": [
        "print(\"F1 score\",f1_score(Y_application['Level2'], (np.array(all_preds)[:, 3]).astype(int), average=None))\n",
        "print(classification_report(Y_application['Level2'], (np.array(all_preds)[:, 3]).astype(int), target_names=['0','1','2','3','4','5','6','7','8']))\n",
        "print('Confusion Matrix \\n' + str(confusion_matrix(Y_application['Level2'], (np.array(all_preds)[:, 3].astype(int)))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edb70858-684b-4d4b-bb03-93407109f17d",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edb70858-684b-4d4b-bb03-93407109f17d",
        "outputId": "3f53d709-adeb-4396-ea69-f9d0d831474c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Critic! [0, 8, 1] 1\n",
            "Critic! [0, 8, 1] 1\n",
            "Critic! [0, 8, 1] 1\n",
            "Critic! [0, 8, 0] 0\n"
          ]
        }
      ],
      "source": [
        "# passing the observations for which the first layer predicts 0 and layer 2 predicts 1\n",
        "all_preds = []\n",
        "for index in range(X_application.shape[0]):\n",
        "    \n",
        "    obs = scaler.transform([X_application.iloc[index].values])\n",
        "    obs = obs.flatten()\n",
        "    final_pred = 0\n",
        "    #first layer:\n",
        "    pred1 = ranForModel.predict([obs])[0]\n",
        "    if pred1 == 0:\n",
        "      pred2 = ensemble.predict([obs])[0]\n",
        "      if pred2 != 0:\n",
        "        pred3 = xgb.predict([obs])[0]\n",
        "        print('Critic! ' + str([pred1, pred2, pred3]) + ' ' + str(Y_application.iloc[index, 0]))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}